# AI Ethics Fairness Audit – COMPAS Dataset 🧠⚖️

This project is part of the PLP Academy AI Ethics assignment under the theme **"Designing Responsible and Fair AI Systems."** It explores bias in the COMPAS dataset and evaluates the fairness of risk prediction models.

## 📌 Objectives

- Identify algorithmic bias in real-world AI systems.
- Perform a fairness audit using IBM’s AI Fairness 360 Toolkit.
- Reflect on responsible AI design and propose ethical solutions.

## 📂 Project Structure

- `notebooks/`: Main Jupyter notebook for bias analysis.
- `reports/`: Theoretical analysis, case studies, and 300-word summary.
- `visuals/`: Plots and charts from the fairness audit.
- `bonus/`: Optional healthcare AI ethics policy.

## 📊 Key Tools

- **Dataset**: COMPAS Recidivism Dataset (from ProPublica)
- **Libraries**: AI Fairness 360, Pandas, Matplotlib, scikit-learn

## 🚀 How to Run

```bash
pip install -r requirements.txt
jupyter notebook notebooks/fairness_audit.ipynb
Team
Evans Kyalo Muendo & Peer Group – PLP Academy

🌐 License
For educational purposes only.

yaml
Copy
Edit

---

## ✅ STEP 2: Add `requirements.txt`

This ensures anyone running your code installs the same packages.

### ➕ Create a file called `requirements.txt` in your root and paste:

```txt
aif360
pandas
matplotlib
scikit-learn
jupyter
