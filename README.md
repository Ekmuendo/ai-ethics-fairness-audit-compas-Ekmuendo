# AI Ethics Fairness Audit â€“ COMPAS Dataset ğŸ§ âš–ï¸

This project is part of the PLP Academy AI Ethics assignment under the theme **"Designing Responsible and Fair AI Systems."** It explores bias in the COMPAS dataset and evaluates the fairness of risk prediction models.

## ğŸ“Œ Objectives

- Identify algorithmic bias in real-world AI systems.
- Perform a fairness audit using IBMâ€™s AI Fairness 360 Toolkit.
- Reflect on responsible AI design and propose ethical solutions.

## ğŸ“‚ Project Structure

- `notebooks/`: Main Jupyter notebook for bias analysis.
- `reports/`: Theoretical analysis, case studies, and 300-word summary.
- `visuals/`: Plots and charts from the fairness audit.
- `bonus/`: Optional healthcare AI ethics policy.

## ğŸ“Š Key Tools

- **Dataset**: COMPAS Recidivism Dataset (from ProPublica)
- **Libraries**: AI Fairness 360, Pandas, Matplotlib, scikit-learn

## ğŸš€ How to Run

```bash
pip install -r requirements.txt
jupyter notebook notebooks/fairness_audit.ipynb
Team
Evans Kyalo Muendo & Peer Group â€“ PLP Academy

ğŸŒ License
For educational purposes only.

yaml
Copy
Edit

---

## âœ… STEP 2: Add `requirements.txt`

This ensures anyone running your code installs the same packages.

### â• Create a file called `requirements.txt` in your root and paste:

```txt
aif360
pandas
matplotlib
scikit-learn
jupyter
